---
title: "A Novel Spatially Aware Loss Function for Microscopy Cell Segmentation"
collection: publications
permalink: /publication/Spatially_Aware_Loss_Function_for_Microscopy_Cell_Segmentation
excerpt: 'Loss functions play a critical role in deep learning-based image segmentation methods, guiding the optimization process to achieve accurate predictions. Conventional loss functions typically compute global differences between the predicted and ground truth segmentation masks. While effective during early training stages, these losses often become trapped in local minima, particularly when small, spatially localized errors are present. Such local misalignments are important for tasks like microscopy cell segmentation but may not significantly impact global loss metrics, leading to suboptimal model performance. To address this limitation, we propose a novel loss function based on spatial moments, which explicitly incorporates local structural variations. This spatially aware formulation enhances sensitivity to fine-grained segmentation errors and promotes better convergence in dense, detail-sensitive biomedical imaging tasks.'
date: 2025-07-27
venue: 'https://mosi2002.github.io/home/'
citation: 'In Preparation'
---
Image segmentation involves assigning a specific label to each pixel in an image. Given its importance in a wide range of applications—including object detection\cite{Object} and medical image analysis\cite{medical1, medical2, medical3}—it has become a fundamental area of research in the field of computer vision.

Nuclei segmentation is a critical step in analyzing nuclear features, which play a key role in detecting abnormal cells or tissues. This analysis supports cancer diagnosis, grading, and the formulation of effective treatment strategies\cite{Nuclei}. The emergence of whole-slide imaging (WSI) combined with advancements in deep learning has significantly advanced automated nuclei segmentation, offering high-resolution digital images and enabling the creation of sophisticated segmentation techniques\cite{WSI, DeepWSI}.

Recent studies have demonstrated the successful application of convolutional neural networks (CNNs) for the automatic segmentation of both 2D and 3D biological data\cite{CNN}. Most current deep learning approaches are based on the fully convolutional network (FCN) archThe widely used U-Net, a variant of the FCN architecture, has become a standard in image segmentation due to its multi-scale skip connections and learnable up-convolution layers\cite{Unet}. Furthermore, several architectures derived from U-Net have shown improved accuracy and performance, highlighting the significance of U-Net-based designs in advancing segmentation tasks\cite{Unet++, transUnet, attUnet, SwinUnet}.

Loss functions serve as the driving force behind model training in image segmentation, shaping how networks learn to distinguish different regions accurately\cite{Loss}. While loss functions play a fundamental role in image segmentation, most widely used ones overlook spatial context and treat each pixel independently. A crucial limitation of these conventional approaches is their inability to account for the spatial arrangement of pixels. This shortcoming becomes especially problematic in scenarios involving densely clustered or closely situated cells, where precise pixel positioning is essential for accurate segmentation.

To address this issue, we propose a novel Spatially Aware Loss Function specifically designed for microscopy cell segmentation, aiming to incorporate spatial dependencies into the learning process and enhance the model's ability to distinguish between adjacent cellular structures.
