---
title: 'MSE vs RNN'
date: 2024-05-08
permalink: /posts/2024/05/MSE-vs-RNN/
tags:
  - Synchronization of Communication systems
  - MSE method
  - RNN, LSTM
---


This Blog post contains comparison study of a Long Short-Term Memory (LSTM) model and a method from this [paper](https://folk.ntnu.no/skoge/prost/proceedings/ifac2008/data/papers/1383.pdf) published by [S. Vahid Naghavi](https://scholar.google.com/citations?user=5bT9h5IAAAAJ&hl=en) for a chaotic system. also i should say as a reminder i used states (x) as a input so these methods can be compared!

## Introduction to main Problem
The importance of synchronization of two coupled chaotic systems was appreciated soon and this topic aroused great interest as a potential mean for **Communication** (kolumban et al, 1997;
Tse et al,2003). In recent years a great deal of effort has been devoted to extend the chaotic communication applications to the field of secure communications. A detailed survey of chaotic secure communication systems is presented by Yang (2004). As the chaos synchronization problem can be reformulated as an observer design problem, the observer-based approach becomes one of the most attractive techniques for chaotic systems. This kind of approach has extensively been investigated in the recent research works by Grassi and Mascolo (2002); Morgul (1996) and Solak (1997) ; Nijmeijer and Mareels (1997); Ushio (1999); Celikovsky and Chen (2002). Neural networks (NNs) have been recognized as valuable tools that offer simple solutions to difficult problems in various science and engineering fields due to their inherent adaptability and universal approximation properties (Suykens, 1996; Luo et al, 1997; Cherkassky et al, 1998). Especially in the area of control, neural networks have experienced an increased interest in the last decade.

## MSE problem Formulation
Refer to the [paper](https://folk.ntnu.no/skoge/prost/proceedings/ifac2008/data/papers/1383.pdf):
Let's assume this system:

\
\begin{cases}
x(k+1) = A \cdot x(k) + B \cdot u(k) + f(x(k), y(k), k) & \text{(State update with input and nonlinearity)} \\

y(k) = C \cdot x(k) + D \cdot u(k) & \text{(Output equation including input contribution)}
\end{cases}
\


## LSTM problem Formulation

## Discussion

## References
<a name="1">[1]</a> Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.

<a name="2">[2]</a> Zhang, K. and Hyvärinen, A., 2016. Nonlinear functional causal models for distinguishing cause from effect. Statistics and Causality; John Wiley & Sons, Inc.: New York, NY, USA, pp.185-201.


<a name="3">[3]</a> Monti, R.P., Zhang, K. and Hyvärinen, A., 2020, August. Causal discovery with general non-linear relationships using non-linear ica. In Uncertainty in artificial intelligence (pp. 186-195). PMLR.

<a name="1">[4]</a> Khemakhem, I., Monti, R., Leech, R. and Hyvarinen, A., 2021, March. Causal autoregressive flows. In International conference on artificial intelligence and statistics (pp. 3520-3528). PMLR.

<a name="1">[5]</a> Lachapelle, S., Brouillard, P., Deleu, T. and Lacoste-Julien, S., 2019. Gradient-based neural dag learning. arXiv preprint arXiv:1906.02226.

<a name="1">[6]</a> Zheng, X., Dan, C., Aragam, B., Ravikumar, P. and Xing, E., 2020, June. Learning sparse nonparametric dags. In International Conference on Artificial Intelligence and Statistics (pp. 3414-3425). PMLR.
